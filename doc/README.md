# SERG: Shifting Euclidean Rhythm Generator

**SERG is a music composition tool inspired by Steve Reich's concept of phase shifting rhythms.**

**It uses Godfried Toussaint's Euclidean Rhythms to create unique musical beats that change over time as they shift in and out of phase.**

## Introduction

### What are Phase Shifting Rhythms

Phase Shifting Rhythms is the name we have given to a technique that Steve Reich uses across his discography.

To explain the concept we will take his piece “Clapping Music for Two Performers” as an example:
* The piece starts with both performers clapping a 1 bar rhythm in unison, repeated 12 times.
* On bar 13 the 1st player continues the rhythm as normal. However, the 2nd player claps a rhythm that is the original rhythm circular shifted by one pulse. Again this is repeated for 12 bars.
* This process of circular shifting is repeated until the 2nd player's rhythm has been shifted back to it's original position.

This simple principle is amazing at producing some very unique feeling rhythmic pieces as the two rhythms go in and out of phase. There is a push-pull effect felt as syncopation is intermittently introduced.
It is this concept of shifting a rhythm over time that our project is based on.

### What are Euclidean Rhythms

Euclidean Rhythm was discovered by Godfried Toussaint in 2004. It uses the Euclidean Algorithm to generate musical rhythms. What is most interesting is that the rhythms it produces are traditional rhythms from all over the world, and rhythms that are found in modern electronic dance music. The greatest common divisor of two numbers is used to create the rhythm where the beats are as equidistant as possible.

The two numbers used to produce the rhythm are called onsets and pulses. Onsets the number of hits/beats in the bar. Pulses describes the number beats in the rhythm or the subdivision of the bar the rhythm is in.

For example 3 onsets, 8 pulses in our context creates a 1 bar rhythm of 1/8th notes with 3 hits in the bar. The resulting rhythm would be “10010010”. A 1 representing an onset and a 0 a silence.  When we look at world music we find this to be the Cuban Tresillo.

Below is a diagram taken from Godfried Toussaint's book The Geometry of Musical Rhythm. It gives a visual description of how the Euclidean Rhythm 3 onsets, 8 pulses is formed.

![cubanTressillo](https://github.com/hfoley03/musical-guacamole/blob/Design_2/img/cubantresillo.png?raw=?)

We chose to use Euclidean Rhythms for our base rhythms as they automatically sound “Good”. As Euclidean Rhythms are ones found throughout music both traditional and modern they contain some invariant quality that is highly agreeable to the listener.

### Terminology

- Onset: a hit or played note during a rhythm.

- Pulse: how the one bar rhythm is subdivided. For example 4 pulses divides the bar into quarter notes, 8 pulses divides the bar into eighth notes.

- Phase Shift Amount: by how many pulses will the rhythm be shifted by.

- Phase Shift Period:  after every how many bars will a shift occur.

- Flavour Notes: the notes in a musical scale not including the root note.


### SERG's Design

SERG has two sets of phase shifting rhythms that are played in sync.

- Set 1 consisting of Track 1 and Track 2
- Set 2 consisting of Track 3 and Track 4.

The base rhythm for each set is generated by a euclidean rhythm. The onsets and pulses can be set independantly

Blah blah blah

## Technical Description

### Technologies Used

#### Tone.js

> Tone.js is a Web Audio framework for creating interactive music in the browser. The architecture of Tone.js aims to be familiar to both musicians and audio programmers creating web-based audio applications.

Tone.js is being used to create an audio context for the project. It provides the building blocks needed to create an audio application in the browser.

#### Tone.js/midi

> Midi makes it straightforward to read and write MIDI files with Javascript. It uses midi-file for parsing and writing.

Tone.js/midi is a library for creating and interacting with Midi data in javascript. It is used in the project to create a four track MIDI file which is then played back in the browser using Tone.js.

#### p5.js

> p5.js is a JavaScript library for creative coding, with a focus on making coding accessible and inclusive for artists, designers, educators, beginners, and anyone else!

P5.js is being used for creating our GUI and for visualising the MIDI data.


### Project Structure

The project is primarily divided among three javasvript files: gui.js, browserPlay.js and midiGeneration.js

- gui.js is responsible for the frontend of the web application.

- browserPlay.js contains the functionality for in browser playback of the midi data using Tone.js.

- midiGeneration.js contains the functionality for generating the rhythmic and melodic data and parsing this data into a Tone.js midi object.

### Flowchart



### GUI
The Graphic User Interface is generated using P5.js. Therefore, it was implemented a circular representation for the rhythms based on the flow of the time as we can see it in a clock, an easy way to understand and visulize Polyrhythms. In that way, the visualization was generated with some functions as described bellow:

#### Fixed_Circles(track):
This function receive as input the number of the Track, Track 1 or Track 3, and draws the main circle taking the binary array of each rhythm generated by the *euclideanPattern()* function. The function subdivides th circle acording to the number of pulses and place the first one at 12 o'clock going respectively, as it is shown in the following figure with 4 onsets and 8 pulses.

![FixedCircle()](https://github.com/hfoley03/musical-guacamole/blob/Design_2/img/FixedCircle.png?raw=?)

#### VisualFix(track):
This function has as input the track number, Track 1 or Track 3, to consider the pulses on the specific track and thus draw an arc to highlight the pulse that is playing in the main circle in clockwise direction, as it is shown in the following figure.

![VisualFixedCircle()](https://github.com/hfoley03/musical-guacamole/blob/Design_2/img/VisualFixedCircle.png?raw=?)

#### ShiftingCircle(x, y, onset, pulses, prt, color1, color2)

The purpose of the function is to draw the circles with the shifting pattern, each one corresponding to a Track bar. Its  imputs are x and y (positions where the circle is locating, onsets (obtained from *GetBinaryShiftedOnset()* function, prt a proportion related with the radio of the circle, color1 and color2.

![ShiftingCircle()](https://github.com/hfoley03/musical-guacamole/blob/Design_2/img/ShiftingCircle.png?raw=?)

#### VisualShift(track)

This function controls the rotation of the circle according to the shifting pattern selected by the user, changing its radio proportion each bar.
First, the *GetBinaryShiftedOnset()* function is called, to takes the Tracks 2 or 4, and obtain a binary representation of the onsets of the full track. Then, the binary array is divided into bars to thus be drawn by *ShiftingCircle()* function.

![VisualShift()](https://github.com/hfoley03/musical-guacamole/blob/Design_2/img/VisualShift.png?raw=?)

For the Timing of the visual functions, there are used two different timers, one for *VisualFix()* based on the pulse duration and one for *VisualShift()* according to the duration of each bar. Consequently, there is one timer corresponding to each set.

```
function VisualFixTimingA();     //Set 1
function VisualFixTimingB();     //Set 2
function VisualShiftTimingA();   //Set 1
function VisualShiftTimingB();   //Set 2
```

These function are sincronized with the audio playing that is way there are used two functions *startTimer()* and *stopTimer()*,which modify the auxiliary variables used to change the parameters in the drawing of the visuals.

### Browser Play

The purpose of the browserPlay.js file is to manage the playback of the created Midi object. The Midi object has four tracks inside, with their own notes to play. Specifically, those notes have attributes of pitch, note duration, starting time, and velocity. The other necessities to play a note are handled in this JavaScript file, such as selecting an instrument to play the note, adjusting the ADSR of the instruments, adding audio effects, connecting the Audio nodes together, and so on.

#### Functions
#### playNotes()
This function is responsible for scheduling the audio events for all tracks. The function is called repeatedly by the function Tone.Loop to play the Midi notes again if the user doesn’t press the button STOP. Therefore, it plays the same Midi notes that are created by the generateMidi() function with the help of looping.
The first step is to set Tone.context.latencyHint to the value of 1 second so that when scheduling the events, it takes time to schedule them as precisely as possible at the expense of a small latency. However, we start by playing the notes 2 seconds later to solve all latency issues. The second step is to record the current time instant with Tone.context.currentTime so that we can start to schedule the audio events exactly after this time instance. Then, for each track in the object, we check the synth_type selected by the user for the Audio playback (this can be both samples and synths). Then we connect these synths to their corresponding channels. If a synth that is not a sample is selected by the dropdown menus on GUI, then for each note in each track, we schedule the audio events by synth.triggerAttackRelease() function with corresponding time instances, note pitches, durations, and velocities. If in the dropdown menus, samples are selected by the user instead of synths, then again for each note in all tracks, synth.start() function is used by their corresponding time instances, durations, and velocities. We don’t consider their corresponding pitch value because they are just buffered samples of percussive instruments.

#### start_aud()
This function starts or resumes the Tone.context, and sets the tempo of the Tone.Transport, sets the volume of the destination of the Tone and calculates and sets the duration of the main loop function. Then, it initiates the main_loop with the calculated loop interval. This function is called when the user presses the START button.
#### stop_aud()
This function first stops the Audio. Then, it cleans the synths array to prevent memory leaks and disposes of the scheduled audio events for each track.

#### Connection of the Audio Nodes
We use channel stripping for all four tracks and their corresponding synths. We connect each synth to a limiter to limit their volumes to a specific value so that the sounds do not pop. Then, we connect the limiter to the chorus effect, delays, and reverb. After the effects, we connect to the destination. The connections are shown in the below figure:


### midiGeneration.js

The generation of the midi object is handled by the javascript file midiGeneration. The process is divided  among several functions, with the function generateMidi handling the overall flow.

#### euclideanPattern(onsets, pulses)

The first step in building the MIDI object for the piece is to create the base Euclidean Rhythm. This is handled by the function euclideanPattern. The function has two input arguments, onsets and pulses. The function returns a string with a binary representation of the Euclidean Rhythm. For example with inputs onsets = 5 and pulses = 8, the function would return
```
“10110110”
```
With a 1 representing an onset and a 0 a pulse without an onset.
The generation of Euclidean Rhythm was designed from the description in Godfried T. Toussaint’s book The Geometry of Musical Rhythm, chapter 19 “Euclidean Rhythms”.
The algorithm was designed from scratch using the method he described. The figure below is taken from The Geometry of Musical Rhythm and shows a visual representation of the algorithm with 5 onsets and 8 pulses.

#### binaryRhythmToMidi(binaryRhythm, midiObject, pulseInTicks, offset)

This function is responsible for transforming the binary string representation of a Euclidean Rhythm into a Tone.js MIDI object. It’s input arguments are binaryRhythm (the binary string of the Euclidean rhythm), midiObject (an empty Tone.js midi object), pulseInTicks (the number of ticks in one pulse) and offset (used to decide if the function is creating tracks 1 & 2 or tracks 3 & 4). It returns a midi object with one bar of Euclidean rhythm in each of the four tracks.

#### createNote(track_, timeTicks, pulseInTicks_)

Adds a midi note to a tracks at a specific time in ticks. The octave of the note depends on the track number. Input arguments are track_ (the track that the note should be added to), timeTicks (when the note should happen in ticks) and pulseInTicks_ (the duration of a pulse in ticks, used to set the length of the note)

#### pitch()

This function is called by createNote to specify what the note letter value will be.
If the user is working in C major with no colour notes selected the function will always return “C”.
If the user has selected colour notes 3 and 5, and with a colour amount of 30%, the function will have a 70% chance of returning “C” and a 30% chance of returning an “E” or “G” (the 3rd and 5th degree of the C Major Scale). These values will change as expected for example if the user specifies D Minor with colour notes 2,4,7.

#### vel()

This function returns a random velocity value for a midi note. The range that this velocity value can be is controlled by the user. If the user has the range at its minium size the function always returns 1.0, max velocity. If the user has the range at 1/4 the values returned will be between 0.75 – 1.0. At maximum range the values returned will be between 0.1 – 1.0.

#### calcScale(key, intervals)

This function creates a scale given a root note and intervals array. The intervals array describes the pattern of intervals in a scale. For example a major scale is represented by
```
let major = [2,2,1,2,2,2,1]
```
#### userSelectedNotes(userSelected, scaleCalculated)

This function reduces the scale created in calcScale to just the notes that the user desires. For example if the user wants C Major with colour notes 4 & 5, the function returns
```
[“C”, “F”, “G”]
```

#### phaseAndCompose(midiInProgress,phaseShiftAmount, phaseShiftPeriod,length)

This function is responsible for creating the MIDI object containing the full composition of all 4 tracks that will be played back in the browser.

Its input arguments are midiInProgress (a MIDI object with four tracks, with each track containing a one bar Euclidean Rhythm), phaseShiftAmount (by how many pulses should a rhythm be shifted by), phaseShiftPeriod(after how many bars should a shift occur) and length (the overall length of the composition in bars).
The function returns the final MIDI object.

The flow chart in fig. x shows a high level flow of this function.

![Image of phaseAndCompose() flowchart](https://github.com/hfoley03/musical-guacamole/blob/Design_2/img/phaseAndComposeDiagram.png?raw=true)


## Challenges

### Challenge 1

give description of challenge, solutions tried and final solution

## Future Work

Things we would like to improve on or change



